{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2Loc Training\n",
    "\n",
    "Description: We propose to lear a descriptor of point clouds for global localization. \n",
    "\n",
    "Author: Lukas Bernreiter (lukas.bernreiter@ieee.org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_source import DataSource\n",
    "from visualize import Visualize\n",
    "from sphere import Sphere\n",
    "from model import Model\n",
    "from loss import TripletLoss\n",
    "from training_set import TrainingSet\n",
    "from average_meter import AverageMeter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Data\n",
    "\n",
    "Load the dataset, project each point cloud on a sphere and derive a function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading anchors from:\t /mnt/data/datasets/Spherical/training-set/training_anchor/\n",
      "Loading positives from:\t /mnt/data/datasets/Spherical/training-set/training_positive/\n",
      "Loading negatives from:\t /mnt/data/datasets/Spherical/training-set/training_negative/\n",
      "Done loading dataset.\n",
      "\tAnchors: \t 10\n",
      "\tPositives: \t 10\n",
      "\tNegatives: \t 10\n"
     ]
    }
   ],
   "source": [
    "ds = DataSource('/mnt/data/datasets/Spherical/training-set')\n",
    "ds.load(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1897ee5645814d7a9888c9833ef22303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5f06b1766e4b318f34516c9f2ee527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JVisualizer with 1 geometries"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_anchor = Sphere(ds.anchors[9])\n",
    "len(first_anchor.point_cloud)\n",
    "\n",
    "viz = Visualize()\n",
    "viz.visualizeRawPointCloud(first_anchor, True)\n",
    "viz.visualizeSphere(first_anchor, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model and the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "net = Model().cuda()\n",
    "restore = 0\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-3, momentum=0.9)\n",
    "n_epochs = 1 #20\n",
    "batch_size = 16\n",
    "num_workers = 1\n",
    "criterion = TripletLoss(margin=2)\n",
    "\n",
    "result_save = 'triplet_result.txt'\n",
    "progress_save = 'triplet_progress.txt'\n",
    "model_save = 'net_params_new_1.pkl'\n",
    "\n",
    "fp = open(result_save,'w')\n",
    "fpp = open(progress_save, 'w')\n",
    "n_parameters = sum([p.data.nelement() for p in net.parameters()])\n",
    "fp.write('Number of params: {}\\n'.format(n_parameters))\n",
    "fp.write('features: [2, 10, 16, 20, 60]\\n')\n",
    "fp.write('bandwidths: [512, 50, 25, 15, 5]\\n')\n",
    "fp.write('batch_size = 16\\n')\n",
    "fp.write('training epoch: 20\\n')\n",
    "fp.write('TripletLoss(margin=2.0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwith = 100\n",
    "train_set = TrainingSet(ds, bandwith)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_exp(optimizer, epoch_num, lr=5e-3):\n",
    "    decay_rate = 0.96\n",
    "    new_lr = lr * math.pow(decay_rate, epoch_num)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished!\n"
     ]
    }
   ],
   "source": [
    "if restore ==0:\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        lr = adjust_learning_rate_exp(optimizer, epoch_num=epoch)\n",
    "        loss_ = 0.0\n",
    "        t0 = time.time()\n",
    "        for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "            data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "            \n",
    "            embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            dista, distb, loss, loss_total = criterion(embedded_a, embedded_p, embedded_n)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_ += loss_total.item()\n",
    "            if batch_idx % 100 == 99:\n",
    "                t1 = time.time()\n",
    "                fpp.write('%.5f\\n' %(loss_ / 100))\n",
    "                print('[Epoch %d, Batch %4d] loss: %.5f time: %.5f lr: %.3e' %\n",
    "                    (epoch + 1, batch_idx + 1, loss_ / 100, (t1-t0) / 60, lr))\n",
    "                t0 = t1\n",
    "                loss_ = 0.0\n",
    "\n",
    "    print('training finished!')\n",
    "    torch.save(net.state_dict(), model_save)\n",
    "    # validating\n",
    "    net.eval()\n",
    "\n",
    "else:\n",
    "    net.load_state_dict(torch.load(model_read))\n",
    "    net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = AverageMeter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
