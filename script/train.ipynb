{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2Loc Training\n",
    "\n",
    "Description: We propose to lear a descriptor of point clouds for global localization. \n",
    "\n",
    "Author: Lukas Bernreiter (lukas.bernreiter@ieee.org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from data_source import DataSource\n",
    "from visualize import Visualize\n",
    "from sphere import Sphere\n",
    "from model import Model\n",
    "from loss import TripletLoss, ImprovedTripletLoss\n",
    "from training_set import TrainingSet\n",
    "from average_meter import AverageMeter\n",
    "from data_splitter import DataSplitter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model and the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "     S2Convolution-1    [-1, 10, 100, 100, 100]              10\n",
      "       BatchNorm3d-2    [-1, 10, 100, 100, 100]              20\n",
      "              ReLU-3    [-1, 10, 100, 100, 100]               0\n",
      "    SO3Convolution-4       [-1, 16, 50, 50, 50]              16\n",
      "              ReLU-5       [-1, 16, 50, 50, 50]               0\n",
      "       BatchNorm3d-6       [-1, 16, 50, 50, 50]              32\n",
      "    SO3Convolution-7       [-1, 20, 30, 30, 30]              20\n",
      "              ReLU-8       [-1, 20, 30, 30, 30]               0\n",
      "       BatchNorm3d-9       [-1, 20, 30, 30, 30]              40\n",
      "   SO3Convolution-10       [-1, 60, 10, 10, 10]              60\n",
      "      BatchNorm3d-11       [-1, 60, 10, 10, 10]             120\n",
      "             ReLU-12       [-1, 60, 10, 10, 10]               0\n",
      "      BatchNorm1d-13                   [-1, 60]             120\n",
      "           Linear-14                  [-1, 256]          15,616\n",
      "             ReLU-15                  [-1, 256]               0\n",
      "      BatchNorm1d-16                  [-1, 256]             512\n",
      "           Linear-17                  [-1, 128]          32,896\n",
      "             ReLU-18                  [-1, 128]               0\n",
      "      BatchNorm1d-19                  [-1, 128]             256\n",
      "           Linear-20                   [-1, 64]           8,256\n",
      "    S2Convolution-21    [-1, 10, 100, 100, 100]              10\n",
      "      BatchNorm3d-22    [-1, 10, 100, 100, 100]              20\n",
      "             ReLU-23    [-1, 10, 100, 100, 100]               0\n",
      "   SO3Convolution-24       [-1, 16, 50, 50, 50]              16\n",
      "             ReLU-25       [-1, 16, 50, 50, 50]               0\n",
      "      BatchNorm3d-26       [-1, 16, 50, 50, 50]              32\n",
      "   SO3Convolution-27       [-1, 20, 30, 30, 30]              20\n",
      "             ReLU-28       [-1, 20, 30, 30, 30]               0\n",
      "      BatchNorm3d-29       [-1, 20, 30, 30, 30]              40\n",
      "   SO3Convolution-30       [-1, 60, 10, 10, 10]              60\n",
      "      BatchNorm3d-31       [-1, 60, 10, 10, 10]             120\n",
      "             ReLU-32       [-1, 60, 10, 10, 10]               0\n",
      "      BatchNorm1d-33                   [-1, 60]             120\n",
      "           Linear-34                  [-1, 256]          15,616\n",
      "             ReLU-35                  [-1, 256]               0\n",
      "      BatchNorm1d-36                  [-1, 256]             512\n",
      "           Linear-37                  [-1, 128]          32,896\n",
      "             ReLU-38                  [-1, 128]               0\n",
      "      BatchNorm1d-39                  [-1, 128]             256\n",
      "           Linear-40                   [-1, 64]           8,256\n",
      "    S2Convolution-41    [-1, 10, 100, 100, 100]              10\n",
      "      BatchNorm3d-42    [-1, 10, 100, 100, 100]              20\n",
      "             ReLU-43    [-1, 10, 100, 100, 100]               0\n",
      "   SO3Convolution-44       [-1, 16, 50, 50, 50]              16\n",
      "             ReLU-45       [-1, 16, 50, 50, 50]               0\n",
      "      BatchNorm3d-46       [-1, 16, 50, 50, 50]              32\n",
      "   SO3Convolution-47       [-1, 20, 30, 30, 30]              20\n",
      "             ReLU-48       [-1, 20, 30, 30, 30]               0\n",
      "      BatchNorm3d-49       [-1, 20, 30, 30, 30]              40\n",
      "   SO3Convolution-50       [-1, 60, 10, 10, 10]              60\n",
      "      BatchNorm3d-51       [-1, 60, 10, 10, 10]             120\n",
      "             ReLU-52       [-1, 60, 10, 10, 10]               0\n",
      "      BatchNorm1d-53                   [-1, 60]             120\n",
      "           Linear-54                  [-1, 256]          15,616\n",
      "             ReLU-55                  [-1, 256]               0\n",
      "      BatchNorm1d-56                  [-1, 256]             512\n",
      "           Linear-57                  [-1, 128]          32,896\n",
      "             ReLU-58                  [-1, 128]               0\n",
      "      BatchNorm1d-59                  [-1, 128]             256\n",
      "           Linear-60                   [-1, 64]           8,256\n",
      "================================================================\n",
      "Total params: 173,922\n",
      "Trainable params: 173,604\n",
      "Non-trainable params: 318\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1953125000.00\n",
      "Forward/backward pass size (MB): 865.20\n",
      "Params size (MB): 0.66\n",
      "Estimated Total Size (MB): 1953125865.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "bandwidth = 100\n",
    "net = Model(bandwidth).cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-3, momentum=0.9)\n",
    "criterion = ImprovedTripletLoss(margin=2, alpha=0.5, margin2=0.2)\n",
    "restore = False\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 12\n",
    "num_workers = 12\n",
    "descriptor_size = 64\n",
    "net_input_size = 2*bandwidth\n",
    "n_features = 2\n",
    "\n",
    "writer = SummaryWriter()\n",
    "model_save = 'net_params_new_1.pkl'\n",
    "\n",
    "print(torch.__version__)\n",
    "summary(net, input_size=[(2, 200, 200), (2, 200, 200), (2, 200, 200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n",
      "foo\n",
      "torch.Size([2, 2, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "grid_size = 2 * bandwidth\n",
    "#np.rand([2,])\n",
    "(a_dummy, p_dummy, n_dummy) = torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size)\n",
    "#traced_net = torch.jit.trace(net, (a_dummy, p_dummy, n_dummy))\n",
    "a_dummy.size(0)    \n",
    "print(\"foo\")\n",
    "for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "    print(\"foo\")\n",
    "    data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()   \n",
    "    print(data1.shape)\n",
    "    embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading anchors from:\t /media/scratch/berlukas/spherical/training/training_anchor/\n",
      "Loading positives from:\t /media/scratch/berlukas/spherical/training/training_positive/\n",
      "Loading negatives from:\t /media/scratch/berlukas/spherical/training/training_negative/\n",
      "Done loading dataset.\n",
      "\tAnchors total: \t\t10\n",
      "\tPositives total: \t10\n",
      "\tNegatives total: \t10\n"
     ]
    }
   ],
   "source": [
    "#ds = DataSource('/mnt/data/datasets/Spherical/training', 1.0)\n",
    "ds = DataSource('/media/scratch/berlukas/spherical/training', 1.0)\n",
    "ds.load(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d009344849fb4848a0875d42110d5ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating positive spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a52a648cf4c678b29513a1dc37213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating negative spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05797b07daa345ae9077b905006d8795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated features\n",
      "total set size:  10\n"
     ]
    }
   ],
   "source": [
    "train_set = TrainingSet(ds, restore, bandwidth)\n",
    "print(\"total set size: \", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  10\n",
      "Training size:  7\n",
      "Validation size:  1\n",
      "Testing size:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Total size: \", len(train_set))\n",
    "split = DataSplitter(train_set, restore, shuffle=True)\n",
    "\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "train_size = split.get_train_size()\n",
    "val_size = split.get_val_size()\n",
    "test_size = split.get_test_size()\n",
    "print(\"Training size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "print(\"Testing size: \", test_size)\n",
    "\n",
    "visualize = False\n",
    "if visualize:\n",
    "    first_anchor = Sphere(ds.anchors_training[0])\n",
    "    len(first_anchor.point_cloud)\n",
    "\n",
    "    viz = Visualize()\n",
    "    viz.visualizeRawPointCloud(first_anchor, True)\n",
    "    viz.visualizeSphere(first_anchor, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0046aff1c187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#(a_dummy, p_dummy, n_dummy) = torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtraced_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_dummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_dummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#torch.onnx.export(net, (a_dummy, p_dummy, n_dummy), \"s2cnn-onnx\", verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    880\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    881\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phaser_ws/src/s2loc/script/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, feature, beta, alpha, gamma]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso3_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/s2cnn-1.0.0-py3.6.egg/s2cnn/soft/s2_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS2_fft_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [l * m, batch, feature_in, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2_rft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [l * m, feature_in, feature_out, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2_mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [l * m * n, batch, feature_out, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/s2cnn-1.0.0-py3.6.egg/s2cnn/soft/s2_fft.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, b_out)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms2_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/s2cnn-1.0.0-py3.6.egg/s2cnn/soft/s2_fft.py\u001b[0m in \u001b[0;36ms2_fft\u001b[0;34m(x, for_grad, b_out)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mwigner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_setup_wigner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfor_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mwigner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [beta, l * m] (2 * b_in, nspec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/s2cnn-1.0.0-py3.6.egg/s2cnn/soft/s2_fft.py\u001b[0m in \u001b[0;36m_setup_wigner\u001b[0;34m(b, nl, weighted, device)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_setup_wigner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_setup_s2_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mdss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [beta, l * m] # pylint: disable=E1102\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/s2cnn-1.0.0-py3.6.egg/s2cnn/soft/s2_fft.py\u001b[0m in \u001b[0;36m_setup_s2_fft\u001b[0;34m(b, nl, weighted)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquadrature_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/lie_learn-0.0.0-py3.6-linux-x86_64.egg/lie_learn/spaces/S3.py\u001b[0m in \u001b[0;36mquadrature_weights\u001b[0;34m(b, grid_type)\u001b[0m\n\u001b[1;32m    183\u001b[0m                               * np.sin((2 * j + 1) * (2 * k + 1)\n\u001b[1;32m    184\u001b[0m                                        * np.pi / (4. * b))))\n\u001b[0;32m--> 185\u001b[0;31m                       for j in range(2 * b)])\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# This is not in the SOFT documentation, but we found that it is necessary to divide by this factor to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/lie_learn-0.0.0-py3.6-linux-x86_64.egg/lie_learn/spaces/S3.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    183\u001b[0m                               * np.sin((2 * j + 1) * (2 * k + 1)\n\u001b[1;32m    184\u001b[0m                                        * np.pi / (4. * b))))\n\u001b[0;32m--> 185\u001b[0;31m                       for j in range(2 * b)])\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# This is not in the SOFT documentation, but we found that it is necessary to divide by this factor to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "grid_size = 2 * bandwidth\n",
    "#np.rand([2,])\n",
    "data = np.random.random_sample((grid_size, grid_size))\n",
    "features = np.zeros([2, 2, grid_size, grid_size]) \n",
    "features[0,0,:] = data; features[0,1,:] = data\n",
    "a_dummy = torch.from_numpy(features)\n",
    "p_dummy = torch.from_numpy(features)\n",
    "n_dummy = torch.from_numpy(features)\n",
    "\n",
    "#(a_dummy, p_dummy, n_dummy) = torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size), torch.rand(1, 2, grid_size, grid_size)\n",
    "traced_net = torch.jit.trace(net, (a_dummy, p_dummy, n_dummy))\n",
    "#torch.onnx.export(net, (a_dummy, p_dummy, n_dummy), \"s2cnn-onnx\", verbose=True)\n",
    "\n",
    "a_dummy.size(0)    \n",
    "print(\"foo\")\n",
    "for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "    print(\"foo\")\n",
    "    data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()   \n",
    "    print(data1.shape)    \n",
    "    embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "    #traced_net = torch.jit.trace(net, (data1, data2, data3))\n",
    "    #torch.onnx.export(net, (data1, data2, data3), \"s2cnn-onnx\", verbose=True)\n",
    "    #print(traced_net)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_exp(optimizer, epoch_num, lr=5e-3):\n",
    "    decay_rate = 0.96\n",
    "    new_lr = lr * math.pow(decay_rate, epoch_num)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "\n",
    "    return new_lr\n",
    "\n",
    "val_accs = AverageMeter()\n",
    "#test_set = TrainingSet(ds, bandwidth, False)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "# record the error of each triplet\n",
    "list_pos = []\n",
    "list_neg = []\n",
    "loss_ = 0\n",
    "\n",
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    # print(pred)\n",
    "    acc = ((pred < 0).sum()).float()/dista.size(0)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def record(dista, distb):\n",
    "    list_pos.append(dista.cpu().data.numpy())\n",
    "    list_neg.append(distb.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, writer, epoch, n_iter, loss_, t0):\n",
    "    net.train()\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()        \n",
    "        embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        dista, distb, loss_triplet, loss_total = criterion(embedded_a, embedded_p, embedded_n)            \n",
    "        loss_embedd = embedded_a.norm(2) + embedded_p.norm(2) + embedded_n.norm(2)\n",
    "        loss = loss_triplet + 0.001 * loss_embedd\n",
    "        #loss = loss_triplet\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ += loss_total.item()\n",
    "\n",
    "        writer.add_scalar('Train/Loss_Triplet', loss_triplet, n_iter)\n",
    "        writer.add_scalar('Train/Loss_Embedd', loss_embedd, n_iter)\n",
    "        writer.add_scalar('Train/Loss', loss, n_iter)            \n",
    "        n_iter += 1\n",
    "    return n_iter\n",
    "\n",
    "def validate(net, criterion, optimizer, writer, epoch, n_iter):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data1, data2, data3) in enumerate(val_loader):\n",
    "            data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()        \n",
    "            embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            dista, distb, loss_triplet, loss_total = criterion(embedded_a, embedded_p, embedded_n)            \n",
    "            loss_embedd = embedded_a.norm(2) + embedded_p.norm(2) + embedded_n.norm(2)\n",
    "            loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "            \n",
    "            acc = accuracy(dista, distb)\n",
    "            val_accs.update(acc, data1.size(0))\n",
    "            writer.add_scalar('Validation/Loss_Triplet', loss_triplet, n_iter)\n",
    "            writer.add_scalar('Validation/Loss_Embedd', loss_embedd, n_iter)\n",
    "            writer.add_scalar('Validation/Loss', loss, n_iter)\n",
    "            writer.add_scalar('Validation/Accuracy', val_accs.avg, n_iter)\n",
    "            n_iter += 1\n",
    "    return n_iter\n",
    "\n",
    "def test(net, criterion, writer):\n",
    "    with open('test_indices.txt','wb') as f:\n",
    "        np.savetxt(f, np.array(split.test_indices), fmt='%d')\n",
    "\n",
    "    n_iter = 0\n",
    "    net.eval()\n",
    "    test_accs = AverageMeter()\n",
    "    test_pos_dist = AverageMeter()\n",
    "    test_neg_dist = AverageMeter()\n",
    "    anchor_embeddings = np.empty(1)\n",
    "    positive_embeddings = np.empty(1)\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "            embedded_a, embedded_p, embedded_n = net(data1.cuda().float(), data2.cuda().float(), data3.cuda().float())\n",
    "            dist_to_pos, dist_to_neg, loss, loss_total = criterion(embedded_a, embedded_p, embedded_n)\n",
    "            writer.add_scalar('Test/Loss', loss, n_iter)\n",
    "\n",
    "            acc = accuracy(dist_to_pos, dist_to_neg)\n",
    "            test_accs.update(acc, data1.size(0))\n",
    "            test_pos_dist.update(dist_to_pos.cpu().data.numpy().sum())\n",
    "            test_neg_dist.update(dist_to_neg.cpu().data.numpy().sum())\n",
    "\n",
    "            writer.add_scalar('Test/Accuracy', test_accs.avg, n_iter)\n",
    "            writer.add_scalar('Test/Distance/Positive', test_pos_dist.avg, n_iter)\n",
    "            writer.add_scalar('Test/Distance/Negative', test_neg_dist.avg, n_iter)\n",
    "\n",
    "            anchor_embeddings = np.append(anchor_embeddings, embedded_a.cpu().data.numpy().reshape([1,-1]))\n",
    "            positive_embeddings = np.append(positive_embeddings, embedded_p.cpu().data.numpy().reshape([1,-1]))\n",
    "            #anchor_embeddings[n_iter] = embedded_a.cpu().data.numpy()\n",
    "            #positive_embeddings[n_iter] = embedded_p.cpu().data.numpy()\n",
    "            n_iter = n_iter + 1\n",
    "\n",
    "    \n",
    "\n",
    "    desc_anchors = anchor_embeddings[1:].reshape([test_size, descriptor_size])\n",
    "    desc_positives = positive_embeddings[1:].reshape([test_size, descriptor_size])\n",
    "\n",
    "    sys.setrecursionlimit(50000)\n",
    "    tree = spatial.KDTree(desc_positives)\n",
    "    p_norm = 2\n",
    "    max_pos_dist = 1.5\n",
    "    max_anchor_dist = 2\n",
    "    for n_nearest_neighbors in range(1,21):\n",
    "        pos_count = 0\n",
    "        anchor_count = 0\n",
    "        idx_count = 0\n",
    "        for idx in range(test_size):\n",
    "            nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "            nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "\n",
    "            for nn_i in nn_indices:\n",
    "                if (nn_i >= test_size):\n",
    "                    break;\n",
    "                dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_positives[idx,:])\n",
    "                if (dist <= max_pos_dist):\n",
    "                    pos_count = pos_count + 1;\n",
    "                    break\n",
    "            for nn_i in nn_indices:\n",
    "                if (nn_i >= test_size):\n",
    "                    break;\n",
    "                dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_anchors[idx,:])\n",
    "                if (dist <= max_anchor_dist):\n",
    "                    anchor_count = anchor_count + 1;\n",
    "                    break\n",
    "            for nn_i in nn_indices:\n",
    "                if (nn_i == idx):\n",
    "                    idx_count = idx_count + 1;\n",
    "                    break\n",
    "        pos_precision = (pos_count*1.0) / test_size\n",
    "        anchor_precision = (anchor_count*1.0) / test_size\n",
    "        idx_precision = (idx_count*1.0) / test_size\n",
    "        writer.add_scalar('Test/Precision/Positive_Distance', pos_precision, n_nearest_neighbors)\n",
    "        writer.add_scalar('Test/Precision/Anchor_Distance', anchor_precision, n_nearest_neighbors)\n",
    "        writer.add_scalar('Test/Precision/Index_Count', idx_precision, n_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using 10 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e28fe9e74594fa18fc51adf6f0ab536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training finished!\n"
     ]
    }
   ],
   "source": [
    "if not restore:    \n",
    "    train_iter = 0\n",
    "    val_iter = 0\n",
    "    loss_ = 0.0\n",
    "    print(f'Starting training using {n_epochs} epochs');\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        lr = adjust_learning_rate_exp(optimizer, epoch_num=epoch)\n",
    "        t0 = time.time()\n",
    "\n",
    "        train_iter = train(net, criterion, optimizer, writer, epoch, train_iter, loss_, t0)\n",
    "\n",
    "        val_iter = validate(net, criterion, optimizer, writer, epoch, val_iter)\n",
    "\n",
    "        writer.add_scalar('Train/lr', lr, epoch)\n",
    "        torch.save(net.state_dict(), model_save)    \n",
    "    print('training finished!')    \n",
    "else:\n",
    "    net.load_state_dict(torch.load(model_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, criterion, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
