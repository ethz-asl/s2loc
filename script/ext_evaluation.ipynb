{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script loads the current model and performs an evaluation of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "First, initialize the model with all parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_source import DataSource\n",
    "from visualize import Visualize\n",
    "from sphere import Sphere\n",
    "from model import Model\n",
    "from loss import TripletLoss, ImprovedTripletLoss\n",
    "from training_set import TrainingSet\n",
    "from average_meter import AverageMeter\n",
    "from data_splitter import DataSplitter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import spatial\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "net = Model().cuda()\n",
    "restore = False\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-3, momentum=0.9)\n",
    "batch_size = 12\n",
    "num_workers = 12\n",
    "descriptor_size = 128\n",
    "bandwidth = 100\n",
    "net_input_size = 2*bandwidth\n",
    "n_features = 3\n",
    "cache = 50\n",
    "criterion = ImprovedTripletLoss(margin=2, alpha=0.5, margin2=0.2)\n",
    "writer = SummaryWriter()\n",
    "stored_model = './net_params_new_1.pkl'\n",
    "net.load_state_dict(torch.load(stored_model))\n",
    "#summary(net, input_size=[(2, 200, 200), (2, 200, 200), (2, 200, 200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading anchors from:\t/media/scratch/berlukas/test/training_anchor_pointclouds/ and /media/scratch/berlukas/test/training_anchor_sph_images/\n",
      "Loading positives from:\t/media/scratch/berlukas/test/training_positive_pointclouds/ and /media/scratch/berlukas/test/training_positive_sph_images/\n",
      "Loading negatives from:\t/media/scratch/berlukas/test/training_negative_pointclouds/ and /media/scratch/berlukas/test/training_negative_sph_images/\n",
      "Done loading dataset.\n",
      "\tAnchor point clouds total: \t127\n",
      "\tAnchor images total: \t\t127\n",
      "\tAnchor poses total: \t\t127\n",
      "\tPositive point clouds total: \t127\n",
      "\tPositive images total: \t\t127\n",
      "\tPositive poses total: \t\t127\n",
      "\tNegative point clouds total: \t127\n",
      "\tNegative images total: \t\t127\n",
      "\tNegative poses total: \t\t127\n"
     ]
    }
   ],
   "source": [
    "n_data = 2000\n",
    "ds = DataSource('/media/scratch/berlukas/test', n_data, -1)\n",
    "ds.load(n_data)\n",
    "n_data = len(ds.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3317c82f06498a9e13f90758e575d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating positive spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41204615b9b4a88b7ba1cf10dbdd3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating negative spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3e9ab23d8b4ddd99daeeb6fdd42056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated features\n",
      "Total size:  127\n"
     ]
    }
   ],
   "source": [
    "test_set = TrainingSet(ds, restore, bandwidth)\n",
    "print(\"Total size: \", len(test_set))\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=False, num_workers=1, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Generate the descriptors for anchor and positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    acc = ((pred < 0).sum()).float()/dista.size(0)\n",
    "    return acc\n",
    "\n",
    "net.eval()\n",
    "n_iter = 0\n",
    "anchor_embeddings = np.empty(1)\n",
    "positive_embeddings = np.empty(1)\n",
    "with torch.no_grad():\n",
    "    test_accs = AverageMeter()\n",
    "    test_pos_dist = AverageMeter()\n",
    "    test_neg_dist = AverageMeter()\n",
    "\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "        embedded_a, embedded_p, embedded_n = net(data1.cuda().float(), data2.cuda().float(), data3.cuda().float())\n",
    "        dist_to_pos, dist_to_neg, loss, loss_total = criterion(embedded_a, embedded_p, embedded_n)\n",
    "        writer.add_scalar('Ext_Test/Loss', loss, n_iter)\n",
    "\n",
    "        acc = accuracy(dist_to_pos, dist_to_neg)\n",
    "        test_accs.update(acc, data1.size(0))\n",
    "        test_pos_dist.update(dist_to_pos.cpu().data.numpy().sum())\n",
    "        test_neg_dist.update(dist_to_neg.cpu().data.numpy().sum())\n",
    "\n",
    "        writer.add_scalar('Ext_Test/Accuracy', test_accs.avg, n_iter)\n",
    "        writer.add_scalar('Ext_Test/Distance/Positive', test_pos_dist.avg, n_iter)\n",
    "        writer.add_scalar('Ext_Test/Distance/Negative', test_neg_dist.avg, n_iter)\n",
    "\n",
    "        anchor_embeddings = np.append(anchor_embeddings, embedded_a.cpu().data.numpy().reshape([1,-1]))\n",
    "        positive_embeddings = np.append(positive_embeddings, embedded_p.cpu().data.numpy().reshape([1,-1]))\n",
    "        n_iter = n_iter + 1\n",
    "        \n",
    "desc_anchors = anchor_embeddings[1:].reshape([n_data, descriptor_size])\n",
    "desc_positives = positive_embeddings[1:].reshape([n_data, descriptor_size])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple old testing pipeline (index based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1fe04141b44336b683a57fd2dff987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.05511811023622047 for 1 neighbors\n",
      "recall 0.14960629921259844 for 2 neighbors\n",
      "recall 0.2283464566929134 for 3 neighbors\n",
      "recall 0.29133858267716534 for 4 neighbors\n",
      "recall 0.3464566929133858 for 5 neighbors\n",
      "recall 0.4330708661417323 for 6 neighbors\n",
      "recall 0.44881889763779526 for 7 neighbors\n",
      "recall 0.4645669291338583 for 8 neighbors\n",
      "recall 0.49606299212598426 for 9 neighbors\n",
      "recall 0.5039370078740157 for 10 neighbors\n",
      "recall 0.5354330708661418 for 11 neighbors\n",
      "recall 0.5590551181102362 for 12 neighbors\n",
      "recall 0.5590551181102362 for 13 neighbors\n",
      "recall 0.5905511811023622 for 14 neighbors\n",
      "recall 0.5984251968503937 for 15 neighbors\n",
      "recall 0.6141732283464567 for 16 neighbors\n",
      "recall 0.6220472440944882 for 17 neighbors\n",
      "recall 0.6377952755905512 for 18 neighbors\n",
      "recall 0.6535433070866141 for 19 neighbors\n",
      "recall 0.6535433070866141 for 20 neighbors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 0.05\n",
    "max_anchor_dist = 1\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):\n",
    "    pos_count = 0\n",
    "    anchor_count = 0\n",
    "    idx_count = 0\n",
    "    for idx in range(n_data):\n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_data):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_positives[idx,:])\n",
    "            if (dist <= max_pos_dist):\n",
    "                pos_count = pos_count + 1;\n",
    "                break\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_data):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_anchors[idx,:])\n",
    "            if (dist <= max_anchor_dist):\n",
    "                anchor_count = anchor_count + 1;\n",
    "                break\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i == idx):\n",
    "                idx_count = idx_count + 1;\n",
    "                break\n",
    "    pos_precision = (pos_count*1.0) / n_data\n",
    "    anchor_precision = (anchor_count*1.0) / n_data\n",
    "    idx_precision = (idx_count*1.0) / n_data\n",
    "    \n",
    "    print(f'recall {idx_precision} for {n_nearest_neighbors} neighbors')\n",
    "    writer.add_scalar('Ext_Test/Precision/Positive_Distance', pos_precision, n_nearest_neighbors)\n",
    "    writer.add_scalar('Ext_Test/Precision/Anchor_Distance', anchor_precision, n_nearest_neighbors)\n",
    "    writer.add_scalar('Ext_Test/Precision/Index_Count', idx_precision, n_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New testing pipeline (location based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test pipeline for a map size of 127 descriptors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87d6fa4f03c45a18cd2f0e012f6bc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.7874015748031497 for 1 neighbors\n",
      "recall 0.8110236220472441 for 2 neighbors\n",
      "recall 0.8267716535433071 for 3 neighbors\n",
      "recall 0.8346456692913385 for 4 neighbors\n",
      "recall 0.8346456692913385 for 5 neighbors\n",
      "recall 0.8582677165354331 for 6 neighbors\n",
      "recall 0.8740157480314961 for 7 neighbors\n",
      "recall 0.8740157480314961 for 8 neighbors\n",
      "recall 0.889763779527559 for 9 neighbors\n",
      "recall 0.889763779527559 for 10 neighbors\n",
      "recall 0.9133858267716536 for 11 neighbors\n",
      "recall 0.9212598425196851 for 12 neighbors\n",
      "recall 0.9212598425196851 for 13 neighbors\n",
      "recall 0.9212598425196851 for 14 neighbors\n",
      "recall 0.9212598425196851 for 15 neighbors\n",
      "recall 0.9212598425196851 for 16 neighbors\n",
      "recall 0.9212598425196851 for 17 neighbors\n",
      "recall 0.9212598425196851 for 18 neighbors\n",
      "recall 0.9212598425196851 for 19 neighbors\n",
      "recall 0.9212598425196851 for 20 neighbors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Running test pipeline for a map size of {len(desc_positives)} descriptors.')\n",
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 3.0\n",
    "max_anchor_dist = 1\n",
    "anchor_poses = ds.anchor_poses\n",
    "positive_poses = ds.positive_poses\n",
    "assert len(anchor_poses) == len(positive_poses)\n",
    "\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):    \n",
    "    loc_count = 0\n",
    "    for idx in range(n_data):\n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_data):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(positive_poses[nn_i,5:8], anchor_poses[idx,5:8])\n",
    "            if (dist <= max_pos_dist):\n",
    "                loc_count = loc_count + 1;\n",
    "                break\n",
    "                \n",
    "    loc_precision = (loc_count*1.0) / n_data    \n",
    "    print(f'recall {loc_precision} for {n_nearest_neighbors} neighbors')\n",
    "    writer.add_scalar('Ext_Test/Precision/Location', loc_precision, n_nearest_neighbors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
