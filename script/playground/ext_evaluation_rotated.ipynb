{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script loads the current model and performs an evaluation of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "First, initialize the model with all parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_source import DataSource\n",
    "from visualize import Visualize\n",
    "from sphere import Sphere\n",
    "from model import Model\n",
    "from loss import TripletLoss, ImprovedTripletLoss\n",
    "from training_set import TrainingSet\n",
    "from average_meter import AverageMeter\n",
    "from data_splitter import DataSplitter\n",
    "from mission_indices import MissionIndices\n",
    "from database_parser import DatabaseParser\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import pyshtools\n",
    "from pyshtools import spectralanalysis\n",
    "from pyshtools import shio\n",
    "from pyshtools import expand\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import scipy.stats as st\n",
    "from scipy import spatial\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "n_features = 2\n",
    "bandwidth = 100\n",
    "from model_relu_old import ModelOld\n",
    "net = ModelOld(n_features, bandwidth).cuda()\n",
    "restore = False\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-3, momentum=0.9)\n",
    "batch_size = 12\n",
    "num_workers = 12\n",
    "descriptor_size = 256\n",
    "net_input_size = 2*bandwidth\n",
    "cache = 50\n",
    "criterion = ImprovedTripletLoss(margin=2, alpha=0.5, margin2=0.2)\n",
    "writer = SummaryWriter()\n",
    "stored_model = './net_params_arche_low_res_small_lidar_only.pkl'\n",
    "net.load_state_dict(torch.load(stored_model))\n",
    "#summary(net, input_size=[(2, 200, 200), (2, 200, 200), (2, 200, 200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading missions db from /home/berlukas/data/arche_low_res2/missions.csv\n",
      "Read 21253 entries.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d1a967731c4d188bfacc969187a79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4c0d91207e47da860c34e4b3f394b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 2 test indices.\n",
      "Loading anchors from:\t/home/berlukas/data/arche_low_res2//training_anchor_pointclouds/ and /home/berlukas/data/arche_low_res2//training_anchor_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14b2018264342c0ab3d91d8a7ac213a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29cb066c5b4422db2c07d2805b1e70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading positives from:\t/home/berlukas/data/arche_low_res2//training_positive_pointclouds/ and /home/berlukas/data/arche_low_res2//training_positive_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a850d800e8ce4597b2d7dc2c0faf09d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4006dce6ca0142279f315729810efb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading negatives from:\t/home/berlukas/data/arche_low_res2//training_negative_pointclouds/ and /home/berlukas/data/arche_low_res2//training_negative_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f24e4cc3a3433fba501a8072671364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df838b17863841d58b6dcd825c83da0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done loading dataset.\n",
      "\tAnchor point clouds total: \t125\n",
      "\tAnchor images total: \t\t125\n",
      "\tAnchor poses total: \t\t125\n",
      "\tPositive point clouds total: \t125\n",
      "\tPositive images total: \t\t125\n",
      "\tPositive poses total: \t\t125\n",
      "\tNegative point clouds total: \t125\n",
      "\tNegative images total: \t\t125\n",
      "\tNegative poses total: \t\t125\n"
     ]
    }
   ],
   "source": [
    "#dataset_path = \"/media/scratch/berlukas/spherical/\"\n",
    "dataset_path = \"/home/berlukas/data/arche_low_res2/\"\n",
    "db_parser = DatabaseParser(dataset_path)\n",
    "\n",
    "training_missions, test_missions = MissionIndices.get_arche_low_res()\n",
    "training_indices, test_indices = db_parser.extract_training_and_test_indices(\n",
    "    training_missions, test_missions)\n",
    "print(f'Found {len(test_missions)} test indices.')\n",
    "\n",
    "n_test_data = 2500\n",
    "n_test_cache = n_test_data\n",
    "ds_test = DataSource(dataset_path, n_test_cache, -1)\n",
    "idx = np.array(test_indices['idx'].tolist())\n",
    "ds_test.load(n_test_data, idx, filter_clusters=True)\n",
    "n_test_data = len(ds_test.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test.rotate_all_positives('z', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features from 0 to 125\n",
      "Generating anchor spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8b11a01941404b8ec1bdeeb57c4e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time in total 29.14858341217041 for 125 anchors.\n",
      "Generating positive spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93a4674cf9749d0861a54bba8429d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time in total 57.29148817062378 for 250 positives.\n",
      "Generating negative spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5339e974a7e846b0a1a319a60dc2713c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time in total 87.14081144332886 for 375 negatives.\n",
      "Generated all pcl features\n",
      "Processing time in total 87.14081144332886 for 375 items.\n",
      "Processing time avg is 0.23238\n"
     ]
    }
   ],
   "source": [
    "test_set = TrainingSet(restore, bandwidth)\n",
    "test_set.generateAll(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  125\n"
     ]
    }
   ],
   "source": [
    "# hack for removing the images\n",
    "test_set.anchor_features = test_set.anchor_features[:,0:2,:,:]\n",
    "test_set.positive_features = test_set.positive_features[:,0:2,:,:]\n",
    "test_set.negative_features = test_set.negative_features[:,0:2,:,:]\n",
    "\n",
    "\n",
    "n_test_set = len(test_set)\n",
    "print(\"Total size: \", n_test_set)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=False, num_workers=1, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Generate the descriptors for anchor and positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    acc = ((pred < 0).sum()).float()/dista.size(0)\n",
    "    return acc\n",
    "\n",
    "net.eval()\n",
    "n_iter = 0\n",
    "anchor_embeddings = np.empty(1)\n",
    "positive_embeddings = np.empty(1)\n",
    "with torch.no_grad():\n",
    "    test_accs = AverageMeter()\n",
    "    test_pos_dist = AverageMeter()\n",
    "    test_neg_dist = AverageMeter()\n",
    "\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "        embedded_a, embedded_p, embedded_n = net(data1.cuda().float(), data2.cuda().float(), data3.cuda().float())\n",
    "        dist_to_pos, dist_to_neg, loss, loss_total = criterion(embedded_a, embedded_p, embedded_n)\n",
    "        writer.add_scalar('Ext_Test/Loss', loss, n_iter)\n",
    "\n",
    "        acc = accuracy(dist_to_pos, dist_to_neg)\n",
    "        test_accs.update(acc, data1.size(0))\n",
    "        test_pos_dist.update(dist_to_pos.cpu().data.numpy().sum())\n",
    "        test_neg_dist.update(dist_to_neg.cpu().data.numpy().sum())\n",
    "\n",
    "        writer.add_scalar('Ext_Test/Accuracy', test_accs.avg, n_iter)\n",
    "        writer.add_scalar('Ext_Test/Distance/Positive', test_pos_dist.avg, n_iter)\n",
    "        writer.add_scalar('Ext_Test/Distance/Negative', test_neg_dist.avg, n_iter)\n",
    "\n",
    "        anchor_embeddings = np.append(anchor_embeddings, embedded_a.cpu().data.numpy().reshape([1,-1]))\n",
    "        positive_embeddings = np.append(positive_embeddings, embedded_p.cpu().data.numpy().reshape([1,-1]))\n",
    "        n_iter = n_iter + 1\n",
    "        \n",
    "desc_anchors = anchor_embeddings[1:].reshape([n_test_set, descriptor_size])\n",
    "desc_positives = positive_embeddings[1:].reshape([n_test_set, descriptor_size])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple old testing pipeline (index based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef256cd8023420d830fdcc781726a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.022222222222222223 for 1 neighbors\n",
      "recall 0.044444444444444446 for 2 neighbors\n",
      "recall 0.06666666666666667 for 3 neighbors\n",
      "recall 0.08888888888888889 for 4 neighbors\n",
      "recall 0.1111111111111111 for 5 neighbors\n",
      "recall 0.13333333333333333 for 6 neighbors\n",
      "recall 0.15555555555555556 for 7 neighbors\n",
      "recall 0.17777777777777778 for 8 neighbors\n",
      "recall 0.2 for 9 neighbors\n",
      "recall 0.2222222222222222 for 10 neighbors\n",
      "recall 0.24444444444444444 for 11 neighbors\n",
      "recall 0.26666666666666666 for 12 neighbors\n",
      "recall 0.28888888888888886 for 13 neighbors\n",
      "recall 0.3111111111111111 for 14 neighbors\n",
      "recall 0.3333333333333333 for 15 neighbors\n",
      "recall 0.35555555555555557 for 16 neighbors\n",
      "recall 0.37777777777777777 for 17 neighbors\n",
      "recall 0.4 for 18 neighbors\n",
      "recall 0.4222222222222222 for 19 neighbors\n",
      "recall 0.4444444444444444 for 20 neighbors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 0.05\n",
    "max_anchor_dist = 1\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):\n",
    "    pos_count = 0\n",
    "    anchor_count = 0\n",
    "    idx_count = 0\n",
    "    for idx in range(n_test_set):\n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_test_set):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_positives[idx,:])\n",
    "            if (dist <= max_pos_dist):\n",
    "                pos_count = pos_count + 1;\n",
    "                break\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_test_set):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(desc_positives[nn_i,:], desc_anchors[idx,:])\n",
    "            if (dist <= max_anchor_dist):\n",
    "                anchor_count = anchor_count + 1;\n",
    "                break\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i == idx):\n",
    "                idx_count = idx_count + 1;\n",
    "                break\n",
    "    pos_precision = (pos_count*1.0) / n_test_set\n",
    "    anchor_precision = (anchor_count*1.0) / n_test_set\n",
    "    idx_precision = (idx_count*1.0) / n_test_set\n",
    "    \n",
    "    print(f'recall {idx_precision} for {n_nearest_neighbors} neighbors')\n",
    "    writer.add_scalar('Ext_Test/Precision/Positive_Distance', pos_precision, n_nearest_neighbors)\n",
    "    writer.add_scalar('Ext_Test/Precision/Anchor_Distance', anchor_precision, n_nearest_neighbors)\n",
    "    writer.add_scalar('Ext_Test/Precision/Index_Count', idx_precision, n_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New testing pipeline (location based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test pipeline for a map size of 125 descriptors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9097aaadc8ec484982ffeeb96805b43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.96 for 1 neighbors\n",
      "recall 0.984 for 2 neighbors\n",
      "recall 0.992 for 3 neighbors\n",
      "recall 0.992 for 4 neighbors\n",
      "recall 0.992 for 5 neighbors\n",
      "recall 0.992 for 6 neighbors\n",
      "recall 0.992 for 7 neighbors\n",
      "recall 0.992 for 8 neighbors\n",
      "recall 0.992 for 9 neighbors\n",
      "recall 0.992 for 10 neighbors\n",
      "recall 0.992 for 11 neighbors\n",
      "recall 0.992 for 12 neighbors\n",
      "recall 0.992 for 13 neighbors\n",
      "recall 0.992 for 14 neighbors\n",
      "recall 0.992 for 15 neighbors\n",
      "recall 0.992 for 16 neighbors\n",
      "recall 0.992 for 17 neighbors\n",
      "recall 0.992 for 18 neighbors\n",
      "recall 0.992 for 19 neighbors\n",
      "recall 1.0 for 20 neighbors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Running test pipeline for a map size of {len(desc_positives)} descriptors.')\n",
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 5.0\n",
    "max_anchor_dist = 1\n",
    "anchor_poses = ds_test.anchor_poses\n",
    "positive_poses = ds_test.positive_poses\n",
    "assert len(anchor_poses) == len(positive_poses)\n",
    "\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):    \n",
    "    loc_count = 0\n",
    "    for idx in range(n_test_set):\n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "\n",
    "        for nn_i in nn_indices:\n",
    "            if (nn_i >= n_test_set):\n",
    "                break;\n",
    "            dist = spatial.distance.euclidean(positive_poses[nn_i,5:8], anchor_poses[idx,5:8])\n",
    "            if (dist <= max_pos_dist):\n",
    "                loc_count = loc_count + 1;\n",
    "                break\n",
    "                \n",
    "    loc_precision = (loc_count*1.0) / n_test_set    \n",
    "    print(f'recall {loc_precision} for {n_nearest_neighbors} neighbors')\n",
    "    #print(f'{loc_precision}')\n",
    "    #writer.add_scalar('Ext_Test/Precision/Location', loc_precision, n_nearest_neighbors)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Voting using Global Spectral Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test pipeline for a map size of 271 descriptors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e9432ca61d44b0b8264f7cbb5440f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9040590405904059\n",
      "0.8966789667896679\n",
      "0.9188191881918819\n",
      "0.9188191881918819\n",
      "0.922509225092251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6c9cd4655548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0ma_range_coeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyshtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHExpandDH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mp_range_coeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyshtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHExpandDH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0ma_intensity_coeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyshtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHExpandDH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_intensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/python/pytorch-venv/lib/python3.6/site-packages/pyshtools/shtools/__init__.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mreturned_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturned_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSHToolsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shtools_status_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturned_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Running test pipeline for a map size of {len(desc_positives)} descriptors.')\n",
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 5.0\n",
    "\n",
    "anchor_poses = ds_test.anchor_poses\n",
    "anchor_clouds = ds_test.anchors\n",
    "anchor_features = test_set.anchor_features\n",
    "\n",
    "positive_poses = ds_test.positive_poses\n",
    "positive_clouds = ds_test.positives\n",
    "positive_features = test_set.anchor_features\n",
    "\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):        \n",
    "    n_matches = 0\n",
    "    loc_count = 0    \n",
    "    for idx in range(0, n_test_set):        \n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "        \n",
    "        z_scores = [0] * n_nearest_neighbors\n",
    "        contains_match = False        \n",
    "        true_match_idx = 0\n",
    "        for i in range(0, n_nearest_neighbors):\n",
    "            nn_i = nn_indices[i]            \n",
    "            if (nn_i >= n_test_set):\n",
    "                print(f'ERROR: index {nn_i} is outside of {n_data}')\n",
    "                break;\n",
    "                \n",
    "            dist = spatial.distance.euclidean(positive_poses[nn_i,5:8], anchor_poses[idx,5:8])\n",
    "            if (dist <= max_pos_dist):\n",
    "                contains_match = True                \n",
    "                true_match_idx = i\n",
    "                \n",
    "            a_range = anchor_features[idx][0,:,:]\n",
    "            p_range = positive_features[nn_i][0,:,:]\n",
    "            a_intensity = anchor_features[idx][1,:,:]\n",
    "            p_intensity = positive_features[nn_i][1,:,:]\n",
    "            #a_img = anchor_features[idx][2,:,:]\n",
    "            #p_img = positive_features[nn_i][2,:,:]\n",
    "                                               \n",
    "            a_range_coeffs = pyshtools.expand.SHExpandDH(a_range, sampling=1)\n",
    "            p_range_coeffs = pyshtools.expand.SHExpandDH(p_range, sampling=1)\n",
    "            \n",
    "            a_intensity_coeffs = pyshtools.expand.SHExpandDH(a_intensity, sampling=1)\n",
    "            p_intensity_coeffs = pyshtools.expand.SHExpandDH(p_intensity, sampling=1)\n",
    "            \n",
    "            #a_img_coeffs = pyshtools.expand.SHExpandDH(a_img, sampling=1)\n",
    "            #p_img_coeffs = pyshtools.expand.SHExpandDH(p_img, sampling=1)\n",
    "            \n",
    "            #a_fused = np.empty([3, a_range_coeffs.shape[0], a_range_coeffs.shape[1]])\n",
    "            #p_fused = np.empty([3, p_range_coeffs.shape[0], p_range_coeffs.shape[1]])\n",
    "            #print(a_range_coeffs.shape)\n",
    "            #a_fused[0,:] = a_range_coeffs\n",
    "            \n",
    "            \n",
    "            admit, error, corr = spectralanalysis.SHAdmitCorr(a_range_coeffs, p_range_coeffs)            \n",
    "            for l in range(0, 4):                \n",
    "                prob = spectralanalysis.SHConfidence(l, corr[l])                \n",
    "                score = st.norm.ppf(1-(1-prob)/2) if prob < 0.99 else 4.0\n",
    "                z_scores[i] = z_scores[i] + score\n",
    "                #if math.isinf(z_scores[i]):\n",
    "                    #print(f'z-score is inf: prob = {prob}, z-score {st.norm.ppf(1-(1-prob)/2)}')\n",
    "            \n",
    "        #if (contains_match is not True):\n",
    "            #print(f'Match not found for index {idx} and {n_nearest_neighbors} neighbors')\n",
    "            #continue\n",
    "        \n",
    "        n_matches = n_matches + 1\n",
    "        max_index, max_z_score = max(enumerate(z_scores), key=operator.itemgetter(1))\n",
    "        matching_index = nn_indices[max_index]\n",
    "        dist = spatial.distance.euclidean(positive_poses[matching_index,5:8], anchor_poses[idx,5:8])\n",
    "        if (dist <= max_pos_dist):\n",
    "            loc_count = loc_count + 1;            \n",
    "        else:\n",
    "            #print(f'Place invalid: distance anchor <-> positive: {dist} with score {max_z_score}.')            \n",
    "            matching_index = nn_indices[true_match_idx]\n",
    "            dist = spatial.distance.euclidean(positive_poses[matching_index,5:8], positive_poses[true_match_idx,5:8])\n",
    "            #print(f'Distance positive <-> true_match: {dist}, true_match score: {z_scores[true_match_idx]}')\n",
    "                \n",
    "    loc_precision = (loc_count*1.0) / n_matches    \n",
    "    #print(f'Recall {loc_precision} for {n_nearest_neighbors} neighbors with {n_matches}/{n_data} correct matches.')\n",
    "    print(f'{loc_precision}')\n",
    "    writer.add_scalar('Ext_Test/Precision/Voting', loc_precision, n_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place Voting using Global Spectral Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test pipeline for a map size of 271 descriptors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9685446a40714ebdaba1fbd263130bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487084870848709\n",
      "0.8560885608856088\n",
      "0.8782287822878229\n",
      "0.8856088560885609\n",
      "0.9003690036900369\n",
      "0.915129151291513\n",
      "0.9040590405904059\n",
      "0.9188191881918819\n",
      "0.9261992619926199\n",
      "0.933579335793358\n",
      "0.9261992619926199\n",
      "0.9261992619926199\n",
      "0.933579335793358\n",
      "0.9298892988929889\n",
      "0.9298892988929889\n",
      "0.9372693726937269\n",
      "0.9372693726937269\n",
      "0.940959409594096\n",
      "0.9446494464944649\n",
      "0.9446494464944649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Running test pipeline for a map size of {len(desc_positives)} descriptors.')\n",
    "sys.setrecursionlimit(50000)\n",
    "tree = spatial.KDTree(desc_positives)\n",
    "p_norm = 2\n",
    "max_pos_dist = 5.0\n",
    "\n",
    "anchor_poses = ds_test.anchor_poses\n",
    "anchor_clouds = ds_test.anchors\n",
    "anchor_features = test_set.anchor_features\n",
    "\n",
    "positive_poses = ds_test.positive_poses\n",
    "positive_clouds = ds_test.positives\n",
    "positive_features = test_set.anchor_features\n",
    "\n",
    "for n_nearest_neighbors in tqdm(range(1,21)):        \n",
    "    n_matches = 0\n",
    "    loc_count = 0    \n",
    "    final_count = 0\n",
    "    for idx in range(0, n_test_set):        \n",
    "        nn_dists, nn_indices = tree.query(desc_anchors[idx,:], p = p_norm, k = n_nearest_neighbors)\n",
    "        nn_indices = [nn_indices] if n_nearest_neighbors == 1 else nn_indices\n",
    "        \n",
    "        z_scores_range = [0] * n_nearest_neighbors\n",
    "        z_scores_intensity = [0] * n_nearest_neighbors\n",
    "        z_scores_image = [0] * n_nearest_neighbors\n",
    "        contains_match = False        \n",
    "        true_match_idx = 0\n",
    "        for i in range(0, n_nearest_neighbors):\n",
    "            nn_i = nn_indices[i]            \n",
    "            if (nn_i >= n_test_set):\n",
    "                print(f'ERROR: index {nn_i} is outside of {n_data}')\n",
    "                break;\n",
    "                \n",
    "            dist = spatial.distance.euclidean(positive_poses[nn_i,5:8], anchor_poses[idx,5:8])\n",
    "            if (dist <= max_pos_dist):\n",
    "                contains_match = True                \n",
    "                true_match_idx = i\n",
    "                \n",
    "            a_range = anchor_features[idx][0,:,:]\n",
    "            p_range = positive_features[nn_i][0,:,:]\n",
    "            a_intensity = anchor_features[idx][1,:,:]\n",
    "            p_intensity = positive_features[nn_i][1,:,:]\n",
    "            #a_img = anchor_features[idx][2,:,:]\n",
    "            #p_img = positive_features[nn_i][2,:,:]\n",
    "                                                           \n",
    "            a_range_coeffs = pyshtools.expand.SHExpandDH(a_range, sampling=1)\n",
    "            p_range_coeffs = pyshtools.expand.SHExpandDH(p_range, sampling=1)\n",
    "            \n",
    "            a_intensity_coeffs = pyshtools.expand.SHExpandDH(a_intensity, sampling=1)\n",
    "            p_intensity_coeffs = pyshtools.expand.SHExpandDH(p_intensity, sampling=1)\n",
    "            \n",
    "            #a_img_coeffs = pyshtools.expand.SHExpandDH(a_img, sampling=1)\n",
    "            #p_img_coeffs = pyshtools.expand.SHExpandDH(p_img, sampling=1)\n",
    "            \n",
    "            tapers, eigenvalues, taper_order = spectralanalysis.SHReturnTapers(2.01, 1)\n",
    "            saa_range = spectralanalysis.spectrum(a_range_coeffs)            \n",
    "            saa_intensity = spectralanalysis.spectrum(a_intensity_coeffs)    \n",
    "            #saa_img = spectralanalysis.spectrum(a_img_coeffs)    \n",
    "            saa = np.empty([n_features, saa_range.shape[0]])\n",
    "            saa[0,:] = saa_range\n",
    "            saa[1,:] = saa_intensity\n",
    "            #saa[2,:] = saa_img\n",
    "            #saa = np.mean(saa, axis=0)\n",
    "            saa = np.amax(saa, axis=0)\n",
    "            \n",
    "            spp_range = spectralanalysis.spectrum(p_range_coeffs)            \n",
    "            spp_intensity = spectralanalysis.spectrum(p_intensity_coeffs)    \n",
    "            #spp_img = spectralanalysis.spectrum(p_img_coeffs)    \n",
    "            spp = np.empty([n_features, spp_range.shape[0]])\n",
    "            spp[0,:] = saa_range\n",
    "            spp[1,:] = saa_intensity\n",
    "            #spp[2,:] = saa_img\n",
    "            #spp = np.mean(spp, axis=0)\n",
    "            spp = np.amax(spp, axis=0)\n",
    "            \n",
    "            sap_range = spectralanalysis.cross_spectrum(a_range_coeffs, p_range_coeffs)            \n",
    "            sap_intensity = spectralanalysis.cross_spectrum(a_intensity_coeffs, p_intensity_coeffs)    \n",
    "            #sap_img = spectralanalysis.cross_spectrum(a_img_coeffs, p_img_coeffs)    \n",
    "            sap = np.empty([n_features, sap_range.shape[0]])\n",
    "            sap[0,:] = saa_range\n",
    "            sap[1,:] = saa_intensity\n",
    "            #sap[2,:] = saa_img\n",
    "            #sap = np.mean(sap, axis=0)\n",
    "            sap = np.amax(sap, axis=0)\n",
    "            \n",
    "            #saa = spectralanalysis.spectrum(a_coeffs)\n",
    "            #spp = spectralanalysis.spectrum(p_coeffs)\n",
    "            #sap = spectralanalysis.cross_spectrum(a_coeffs, p_coeffs)\n",
    "            \n",
    "            #admit, corr = spectralanalysis.SHBiasAdmitCorr(sap_img, saa_img, spp_img, tapers)            \n",
    "            #admit, corr = spectralanalysis.SHBiasAdmitCorr(sap, saa, spp, tapers)\n",
    "            \n",
    "            admit, corr = spectralanalysis.SHBiasAdmitCorr(sap_range, saa_range, spp_range, tapers)                        \n",
    "            for l in range(0, 10):                \n",
    "                prob = spectralanalysis.SHConfidence(l, corr[l])                \n",
    "                score = st.norm.ppf(1-(1-prob)/2) if prob < 0.99 else 4.0\n",
    "                z_scores_range[i] = z_scores_range[i] + score\n",
    "                            \n",
    "            admit, corr = spectralanalysis.SHBiasAdmitCorr(sap_intensity, saa_intensity, spp_intensity, tapers)                            \n",
    "            for l in range(0, 10):                \n",
    "                prob = spectralanalysis.SHConfidence(l, corr[l])                \n",
    "                score = st.norm.ppf(1-(1-prob)/2) if prob < 0.99 else 4.0\n",
    "                z_scores_intensity[i] = z_scores_intensity[i] + score                           \n",
    "            \n",
    "        #if (contains_match is not True):\n",
    "            #print(f'Match not found for index {idx} and {n_nearest_neighbors} neighbors')\n",
    "            #continue\n",
    "        \n",
    "        n_matches = n_matches + 1\n",
    "        max_index_range, max_z_score_range = max(enumerate(z_scores_range), key=operator.itemgetter(1))\n",
    "        max_index_intensity, max_z_score_intensity = max(enumerate(z_scores_intensity), key=operator.itemgetter(1))\n",
    "        \n",
    "        #print(f'max range: {max_z_score_range}, max intensity: {max_z_score_intensity}')\n",
    "        max_index = max_index_range if max_z_score_range > max_z_score_intensity else max_index_intensity\n",
    "        matching_index = nn_indices[max_index]\n",
    "        dist = spatial.distance.euclidean(positive_poses[matching_index,5:8], anchor_poses[idx,5:8])\n",
    "        if (dist <= max_pos_dist):\n",
    "            loc_count = loc_count + 1;            \n",
    "        else:\n",
    "            #print(f'Place invalid: distance anchor <-> positive: {dist} with score {max_z_score}.')            \n",
    "            matching_index = nn_indices[true_match_idx]\n",
    "            dist = spatial.distance.euclidean(positive_poses[matching_index,5:8], positive_poses[true_match_idx,5:8])\n",
    "            #print(f'Distance positive <-> true_match: {dist}, true_match score: {z_scores[true_match_idx]}')\n",
    "                \n",
    "    loc_precision = (loc_count*1.0) / n_matches    \n",
    "    #print(f'Recall {loc_precision} for {n_nearest_neighbors} neighbors with {n_matches}/{n_data} correct matches.')\n",
    "    print(f'{loc_precision}')\n",
    "    writer.add_scalar('Ext_Test/Precision/WindowedVoting', loc_precision, n_nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_poses[0:100,5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matrix('1 2; 3 4')\n",
    "b = np.matrix('4 5; 6 7')\n",
    "c = np.empty([2,2,2])\n",
    "c[0,:,:] = a\n",
    "c[1,:,:] = b\n",
    "np.mean(c, axis=0)\n",
    "a.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
