{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHTools Demo\n",
    "\n",
    "This notbook is used to play around with a few things from the pyshtools library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyshtools\n",
    "from pyshtools import spectralanalysis\n",
    "from pyshtools import shio\n",
    "from pyshtools import expand\n",
    "\n",
    "from s2cnn import S2Convolution\n",
    "from s2cnn import s2_fft\n",
    "from s2cnn.utils.complex import as_complex\n",
    "\n",
    "from training_set import TrainingSet\n",
    "from data_source import DataSource\n",
    "from visualize import Visualize\n",
    "from sphere import Sphere\n",
    "from model import Model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input\n",
    "First, load the current input feature set from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore = False\n",
    "bandwidth = 100\n",
    "dataset_path = \"/media/scratch/berlukas/spherical/\"\n",
    "#dataset_path = \"/home/berlukas/data/arche_low_res/\"\n",
    "\n",
    "n_test_data = 20\n",
    "n_test_cache = n_test_data\n",
    "ds_test = DataSource(dataset_path, n_test_cache, -1)\n",
    "ds_test.load(n_test_data)\n",
    "n_test_data = len(ds_test.anchors)\n",
    "test_set = TrainingSet(restore, bandwidth)\n",
    "test_set.generateAll(ds_test)\n",
    "n_test_set = len(test_set)\n",
    "print(\"Total size: \", n_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a S2 transform of the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "coeff = None\n",
    "for batch_idx, data in enumerate(loader): \n",
    "    print(batch_idx)\n",
    "    #s2_fft.S2_fft_real.apply(data[0], 50)\n",
    "    a = data[0].float()[0,2,:,:]\n",
    "    p = data[1].float()[0,2,:,:]\n",
    "    n = data[2].float()[0,2,:,:]\n",
    "    print(a.shape)\n",
    "    print(as_complex(a).shape)\n",
    "    #A = s2_fft.s2_fft(as_complex(a))\n",
    "    #print(A.shape)\n",
    "    #print(A[0,:])\n",
    "    if batch_idx == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = torch.transpose(a, 0,1)\n",
    "#grid = as_complex(torch.transpose(a, 0,1))\n",
    "#grid = torch.reshape(grid, (grid.size(2), grid.size(0), grid.size(1)))\n",
    "#a_grid = pyshtools.expand.MakeGridDH(grid, sampling=1)\n",
    "a_coeffs = pyshtools.expand.SHExpandDH(a, sampling=1)\n",
    "power_per_l = pyshtools.spectralanalysis.spectrum(a_coeffs)\n",
    "degrees = np.arange(a_coeffs.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(degrees, power_per_l)\n",
    "ax.set(yscale='log', xscale='log', xlabel='Spherical harmonic degree', ylabel='Power')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = torch.transpose(p, 0,1)\n",
    "#grid = as_complex(torch.transpose(p, 0,1))\n",
    "#grid = torch.reshape(grid, (grid.size(2), grid.size(0), grid.size(1)))\n",
    "#p_grid = pyshtools.expand.MakeGridDH(grid, sampling=1)\n",
    "p_coeffs = pyshtools.expand.SHExpandDH(p, sampling=1)\n",
    "power_per_l = spectralanalysis.cross_spectrum(a_coeffs, p_coeffs, normalization='schmidt', convention='energy')\n",
    "degrees = np.arange(a_coeffs.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(degrees, power_per_l)\n",
    "ax.set(yscale='log', xscale='log', xlabel='Spherical harmonic degree', ylabel='Power')\n",
    "ax.grid()\n",
    "\n",
    "admit, error, corr = spectralanalysis.SHAdmitCorr(a_coeffs, p_coeffs)\n",
    "for i in range(0, 100):\n",
    "    prob = spectralanalysis.SHConfidence(i, corr[i])\n",
    "    if (prob < 1.0):\n",
    "        print(f'Probability of being correlated at {i} is {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = torch.transpose(n, 0,1)\n",
    "#grid = as_complex(torch.transpose(n, 0,1))\n",
    "#grid = torch.reshape(grid, (grid.size(2), grid.size(0), grid.size(1)))\n",
    "#n_grid = pyshtools.expand.MakeGridDH(grid, sampling=1)\n",
    "n_coeffs = pyshtools.expand.SHExpandDH(n, sampling=1)\n",
    "power_per_l = spectralanalysis.cross_spectrum(a_coeffs, n_coeffs, normalization='schmidt', convention='energy')\n",
    "degrees = np.arange(a_coeffs.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(degrees, power_per_l)\n",
    "ax.set(yscale='log', xscale='log', xlabel='Spherical harmonic degree', ylabel='Power')\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "admit, error, corr = spectralanalysis.SHAdmitCorr(a_coeffs, n_coeffs)\n",
    "for i in range(0, 100):\n",
    "    prob = spectralanalysis.SHConfidence(i, corr[i])\n",
    "    if (prob < 1.0):\n",
    "        print(f'Probability of being correlated at {i} is {prob}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
